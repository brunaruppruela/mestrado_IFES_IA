{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98542a84",
   "metadata": {},
   "source": [
    "# Instalacao das dependencias e Importacao das bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf22a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gymnasium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"stable-baselines3[extra]\"\n",
    "! pip install -q swig\n",
    "! pip install -q \"gymnasium[box2d]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from collections import defaultdict\n",
    "\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dd83dd",
   "metadata": {},
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb20370e",
   "metadata": {},
   "source": [
    "Esses parâmetros são configurados para balancear o desempenho e a estabilidade do treinamento do agente PPO no ambiente CarRacing-v2. Ajustar esses hiperparâmetros pode ser necessário para otimizar o desempenho do agente para tarefas específicas e pode requerer experimentação baseada nos resultados de treinamento e nos gráficos de desempenho observados através do TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ceca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"CnnPolicy\", 'CarRacing-v2',#Arquitetura da rede neural e ambiente de treinamento\n",
    "            tensorboard_log = 'training/logs', #Diretório onde os logs do TensorBoard serão armazenados.\n",
    "            batch_size = 512, #Tamanho do lote de amostras usadas em cada atualização de gradiente. Um tamanho de lote maior pode levar a uma estimativa mais estável do gradiente, mas também requer mais memória e pode tornar o treinamento mais lento.\n",
    "            clip_range = 0.2, #valor de clipe para a probabilidade de razão.\n",
    "            ent_coef = 0.0, #Coeficiente de entropia. A entropia é usada para incentivar a exploração adicionando uma penalidade por políticas determinísticas. Um valor de 0.0 significa que não há incentivo adicional para a exploração.\n",
    "            gae_lambda = 0.95,#O fator lambda para o Generalized Advantage Estimation (GAE).\n",
    "            gamma = 0.99, #Fator de desconto. Um valor de 0.99 significa que o agente valoriza mais as recompensas futuras próximas. É um fator comum em muitos problemas de aprendizado por reforço.\n",
    "            learning_rate = 0.0003,#Taxa de aprendizado do otimizador.Define a velocidade com que o modelo se ajusta aos gradientes. Um valor de 0.0003 é um ponto de partida comum, proporcionando um bom equilíbrio entre a convergência rápida e a estabilidade do treinamento.\n",
    "            max_grad_norm = 0.5,#Norma máxima para os gradientes. Clipping dos gradientes para evitar explosões de gradiente, que podem desestabilizar o treinamento. Um valor de 0.5 é frequentemente utilizado para manter os gradientes sob controle.\n",
    "            n_epochs = 10)#Número de épocas para cada atualização de política. Define quantas vezes o modelo passa pelos dados de treinamento em cada atualização. Mais épocas podem levar a um melhor ajuste, mas também aumentam o tempo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps = 1000000, log_interval = 5, progress_bar = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4374d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('training/trained_models3/PPO_400kCarRacing_whp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', render_mode = 'rgb_array')\n",
    "env = DummyVecEnv([lambda : env])\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a8d72",
   "metadata": {},
   "source": [
    "## Criacao dos videos para interpretar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879423f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenCV library\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93656491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o ambiente CarRacing-v2 do Gym e inicializa com o modo de renderização rgb_array\n",
    "env = gym.make('CarRacing-v2', render_mode='rgb_array')\n",
    "# Cria um DummyVecEnv para compatibilidade com o stable_baselines3\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Define parâmetros do vídeo\n",
    "width, height = 600, 400  # Largura e altura do vídeo\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec para compressão do vídeo\n",
    "video_writer = cv2.VideoWriter(\"Car Racing3.mp4\", fourcc, 30.0, (width, height))  # Inicializa o gravador de vídeo\n",
    "\n",
    "# Número de episódios a serem gravados\n",
    "episodes = 10\n",
    "\n",
    "# Loop sobre os episódios\n",
    "for episode in range(1, episodes + 1):\n",
    "    # Reinicia o ambiente para o início de um novo episódio\n",
    "    observation = env.reset()\n",
    "    done, score = False, 0  # Inicializa variáveis de controle\n",
    "\n",
    "    # Loop até que o episódio termine\n",
    "    while not done:\n",
    "        # Prediz a ação usando o modelo treinado\n",
    "        action, _ = model.predict(observation)\n",
    "        step = env.step(action)  # Executa a ação no ambiente\n",
    "\n",
    "        # Extrai informações do passo retornado pelo ambiente\n",
    "        observation, reward, done, info = step[0], step[1], step[2], step[3]\n",
    "        score += reward  # Acumula a recompensa\n",
    "\n",
    "        # Grava o ambiente\n",
    "        frame = env.render()  # Renderiza o ambiente e obtém o frame\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Converte o frame de RGB para BGR\n",
    "        frame = cv2.resize(frame, (width, height))  # Redimensiona o frame para as dimensões desejadas\n",
    "\n",
    "        # Escreve o frame no vídeo\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    # Exibe a pontuação do episódio\n",
    "    print(f\"Episode {episode} score: {score}\")\n",
    "\n",
    "# Libera o gravador de vídeo\n",
    "video_writer.release()\n",
    "# Fecha o ambiente\n",
    "env.close()\n",
    "# Destroi todas as janelas do OpenCV\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653be00",
   "metadata": {},
   "source": [
    "## Ler o modelo ja treinado ou buscar da pasta - para salvar um novo treinamento alterar o nome da pasta trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce020c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('training/trained_models3/PPO_400kCarRacing_whp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025eb957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-31e694fca2c07b82\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-31e694fca2c07b82\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir training/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06dc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', render_mode = 'rgb_array')\n",
    "env = DummyVecEnv([lambda : env])\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd45b6",
   "metadata": {},
   "source": [
    "# Ler os videos das pastas salvas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100bf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1651e71",
   "metadata": {},
   "source": [
    "Leitura do video - trocar os nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display, clear_output, Image\n",
    "\n",
    "def display_video(video_path):\n",
    "    # Abre o vídeo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Lê um quadro do vídeo\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Converte a imagem de BGR (usado pelo OpenCV) para RGB (usado pelo Jupyter)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Converte o quadro para imagem no formato que o Jupyter aceita\n",
    "        _, img = cv2.imencode('.jpg', frame)\n",
    "        display(Image(data=img.tobytes()))\n",
    "        \n",
    "        # Limpa a saída para o próximo quadro\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Chama a função passando o caminho do vídeo\n",
    "display_video('Car Racing3.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80bee3",
   "metadata": {},
   "source": [
    "Resolver o problema do display trazendo como widget do Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7df4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
